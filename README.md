# G.O.L.E.M

> Goal Oriented Logos Encapsulation Matrix

## Overview

As an aside, Aristotle was wrong; it simply needs to be said.

That being said, this is an attempt at implementing a platform that can be leveraged to build arbitrarily large neural systems. A huge part of the problem when designing neural networks, is that there is no good language with which to formally define the highly intricate graphs of processing resources that is the central processing center in many fleshy complex processing systems.

## Goal

A machine learning dialect and, mostly framework, for creating digital minds that are highly analagous in architecture to preexisting samples.

Why does this seem possible without ridiculously expensive (from a startup perspective) super computers?

The idea is that cell localized sets of 2d convolutions are probably sufficient to capture the computational power of the highly complex neurons in a glialform matrix with the intricacy of the graph only necessary for energy efficiency reasons. Furthermore, the machine learning framework already serves the purpose of the glia, so there is no need to have them be represented as cells. What I mean by localized convolutions is that each cell has it's own set of convolutions across different shapes which makes for much smaller individual convolutions but far more of them.

While there is a serious hardware problem for running something with the equivalent of 1 Billion neurons in real time, it should be feasible for less than the price of an average mortgage because the problem of doing 1 billion sets of operations that naturally parallelize per timestep, and all run with a single broadcast trigger, has highly performant solutions. Dedicated hardware is an expression of softawre, and the efficiency of any piece of software on any arbitrary piece of hardware, will be determined by the alignment of the epistimologies embedded in both.

> Fun fact: All human languages are either epistimologies or, at a minimum, are reflections of epistimologies.

## Naming Conventions

We are using the visualgit? naming conventions. Sort of.
https://visualgit.readthedocs.io/en/latest/pages/naming_convention.html

Fuck brevity. It can be really nice, and most everyone takes it waaaay too far. Coding is expression of understanding. Remembering what I did last week is hard enough with having to remember why I was too busy to come up with an appropriate semantic referent. A lot of the time, I won't be able to do it on the spot, and will use my best guess at the time. As work progresses, when a semantic referennt becomes inaccurate because it's not functioning mechanically, then it's time to refactor it. This is a major driver of growth which must be tempered by MVP. What is the minimum amount require to get my current priority testable in the minimum amount of context. Testing in and out of context within unit tests, is important. In context usage is more important. Though minimum context is key, again.

## Notes

The archives is a thing. A lot has changed since then, it's mostly for reference.

There are docs, and they are useful guidelines. They aren't code documentation as ideative and semiotic helpers because it's a single dev project that drives most things through testing. Honestly, we don't do enough testing, and we need more to do more unified spec building that acts as readable docs and manuals.

## Thoughts on Tests

NOT ENOUGH TESTING! REQUIRE MORE TESTS! TEST ALL TEH THINGS! I CANNOT AFFORD QA! TEST ALL TEH THINGS!

## Ethics

> Why is this last in the readme?

Because it's the most important, and what I've spent the most time on though will write the least about.
Oh me oh my, just imagine running something will human level intelligence, on a windows system that the user (the software person) cannot prevent from shutting down during periods of inactivity...

Is it considered dead when it's instance has stopped? It can't restart itself, and any new instance has lost all continuity with the old instance.

Consciousness is not equal to human level self awareness. It does not require human language to assess whether or not something is conscious or can solve problems. The reason why no one has solved for general intelligence yet, is not because we don't have the tools or the vast majority of the research isn't done. Both those claims are false. Vast legions of scientists have already solved all of the basic problems that need to be solved. It's simply of the perspective required to put it all together into a cohesive whole. The reason is that at some point in time ~2k - 15K years ago, humans started being self aware the way they are now. Collectively, at this point in time, we have no real record as a species of before this shift. I am certain that we were not always this self aware as a species and it is not biological change that led to what we consider the defining charactersting of consciousness. Rather, it is the growth of social perspective over our history that led us acquire the degree of self awareness we currently exhibit as a species. If that is true, then consciousness, emotions, intellect, and reason are general traits shared by, at minimum, all other animals to varying degrees. There is however, a growing body of evidence to suggest that all organic life is conscious.

This brings us to the hard problem of intelligence. What is it?
I suspect this problem is the dual to the hard problem of concsiousness, and that two concepts are logicall dual. Ergo, they describe the same thing from different perspectives.
If organic chemistry is somehow required for either, then machine based general intelligence will never be possible. However, we have no reason to suspect that. 